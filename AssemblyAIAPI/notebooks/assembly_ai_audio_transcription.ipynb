{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Transcription using AssemblyAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "from pprint import pprint\n",
    "from textwrap import wrap\n",
    "from urllib.parse import urlencode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename, chunk_size=5242880):\n",
    "    # Open the file in binary mode for reading\n",
    "    with open(filename, 'rb') as _file:\n",
    "        while True:\n",
    "            # Read a chunk of data from the file\n",
    "            data = _file.read(chunk_size)\n",
    "            # If there's no more data, stop reading\n",
    "            if not data:\n",
    "                break\n",
    "            # Yield the data as a generator\n",
    "            yield data\n",
    "\n",
    "def upload_file(api_token, path):\n",
    "    \"\"\"\n",
    "    Upload a file to the AssemblyAI API.\n",
    "\n",
    "    Args:\n",
    "        api_token (str): Your API token for AssemblyAI.\n",
    "        path (str): Path to the local file.\n",
    "\n",
    "    Returns:\n",
    "        str: The upload URL.\n",
    "    \"\"\"\n",
    "    print(f\"Uploading file: {path}\")\n",
    "\n",
    "    # Set the headers for the request, including the API token\n",
    "    headers = {'authorization': api_token}\n",
    "    \n",
    "    # Send a POST request to the API to upload the file, passing in the headers\n",
    "    # and the file data\n",
    "    response = requests.post('https://api.assemblyai.com/v2/upload',\n",
    "                             headers=headers,\n",
    "                             data=read_file(path))\n",
    "\n",
    "    # If the response is successful, return the upload URL\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"upload_url\"]\n",
    "    # If the response is not successful, print the error message and return\n",
    "    # None\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "def get_segment(transcript_id, segmentation_type, headers):\n",
    "    if segmentation_type in [\"sentences\", \"paragraphs\"]:\n",
    "        endpoint = f\"https://api.assemblyai.com/v2/transcript/{transcript_id}/{segmentation_type}\"\n",
    "        response = requests.get(endpoint, headers=headers)\n",
    "        if response.status_code==200:\n",
    "            response_json = json.loads(response.text)\n",
    "            return response_json\n",
    "        else:\n",
    "            print(f\"Error {response.status_code}: {response.text}\")\n",
    "            return None\n",
    "    else:\n",
    "        raise Exception(f\"Unknown segmentation type: {segmentation_type}\")\n",
    "\n",
    "    \n",
    "def export_transcript_to_srt_vtt_file(transcript_id, headers, format=\"vtt\", transcript_export_params=None):\n",
    "    if format not in [\"srt\", \"vtt\"]:\n",
    "        raise ValueError(\"unknown format for exporting transcript\")\n",
    "    endpoint = f\"https://api.assemblyai.com/v2/transcript/{transcript_id}/{format}\"\n",
    "    if transcript_export_params is None:\n",
    "        transcript_export_params = {\n",
    "            \"chars_per_caption\": 32\n",
    "        }\n",
    "    response = requests.get(endpoint, headers=headers, params=transcript_export_params)\n",
    "    return response.text\n",
    "\n",
    "def transcript_word_search(transcript_id, words, headers):\n",
    "    params = {\n",
    "        \"words\": json.dumps(words)\n",
    "    }\n",
    "    endpoint = f\"https://api.assemblyai.com/v2/transcript/{transcript_id}/word-search?{urlencode(params)}\"\n",
    "    \n",
    "    response = requests.get(endpoint, headers=headers, params=params)\n",
    "    return response.text\n",
    "    \n",
    "\n",
    "def create_transcript(api_token, \n",
    "                      data,\n",
    "                      export_format=None,\n",
    "                      transcript_export_params=None,\n",
    "                      words_to_search=None,\n",
    "                      segmentation_type=None\n",
    "                      ):\n",
    "\n",
    "    # Set the API endpoint for creating a new transcript\n",
    "    url = \"https://api.assemblyai.com/v2/transcript\"\n",
    "\n",
    "    # Set the headers for the request, including the API token and content type\n",
    "    headers = {\n",
    "        \"authorization\": f'Bearer {api_token}',\n",
    "        \"content-type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Send a POST request to the API to create a new transcript, passing in the\n",
    "    # headers and data\n",
    "    response = requests.post(url, json=data, headers=headers)\n",
    "\n",
    "    # Get the transcript ID from the response JSON data\n",
    "    transcript_id = response.json()['id']\n",
    "\n",
    "    # Set the polling endpoint URL by appending the transcript ID to the API endpoint\n",
    "    polling_endpoint = f\"https://api.assemblyai.com/v2/transcript/{transcript_id}\"\n",
    "\n",
    "    # Keep polling the API until the transcription is complete\n",
    "    while True:\n",
    "        # Send a GET request to the polling endpoint, passing in the headers\n",
    "        transcription_result = requests.get(polling_endpoint, headers=headers).json()\n",
    "\n",
    "        # If the status of the transcription is 'completed', exit the loop\n",
    "        if transcription_result['status'] == 'completed':\n",
    "            break\n",
    "\n",
    "        # If the status of the transcription is 'error', raise a runtime error with\n",
    "        # the error message\n",
    "        elif transcription_result['status'] == 'error':\n",
    "            raise RuntimeError(f\"Transcription failed: {transcription_result['error']}\")\n",
    "\n",
    "        # If the status of the transcription is not 'completed' or 'error', wait for\n",
    "        # 3 seconds and poll again\n",
    "        else:\n",
    "            time.sleep(3)\n",
    "        \n",
    "    output = (transcription_result,)\n",
    "    if words_to_search is not None:\n",
    "            word_search_response = transcript_word_search(transcript_id, words_to_search, headers=headers)\n",
    "            output = output + (word_search_response,)\n",
    "    else:\n",
    "        output += (None,)\n",
    "        raise Exception(\"words not found for searching\")\n",
    "    \n",
    "    if export_format is not None:\n",
    "        transcript_tobe_exported = export_transcript_to_srt_vtt_file(transcript_id, headers, format=export_format, transcript_export_params=transcript_export_params)\n",
    "        output = output + (transcript_tobe_exported,)\n",
    "    else:\n",
    "        output = output + (None,)\n",
    "        \n",
    "    if segmentation_type is not None:\n",
    "        segmented_transcript = get_segment(transcript_id, segmentation_type, headers)\n",
    "        output = output + (segmented_transcript,)\n",
    "    else:\n",
    "        output = output + (None,)\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters and function calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------\n",
    "# Your API token is already set in this variable\n",
    "your_api_token = \"\"\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Cutom Vocabulary\n",
    "custom_spellings = [\n",
    "    {\n",
    "        \"from\": [\"ryan pace\"],\n",
    "        \"to\": [\"Ryan Pace\"]\n",
    "    },\n",
    "    {\n",
    "        \"from\": [\"matt naggy\"],\n",
    "        \"to\": [\"Matt Naggy\"]\n",
    "    }\n",
    "]\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Cutom Vocabulary\n",
    "word_boost = [\"quarterback\", \"veteran\"]\n",
    "boost_param = \"high\"\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Upload the file to AssemblyAI and get the upload URL\n",
    "# You may also remove the upload step and update the 'audio_url' parameter in the\n",
    "# 'create_transcript' function to point to a remote audio or video file.\n",
    "# If you don't have one, download a sample file: https://storage.googleapis.com/aai-web-samples/espn-bears.m4a\n",
    "filename = \"../data/sample.m4a\"\n",
    "upload_url = upload_file(your_api_token, filename)\n",
    "# ----------------------------------------------------------------------------------\n",
    "data = {\n",
    "    \"audio_url\": upload_url,    # url of uploaded audio file\n",
    "    \"language_code\": \"en\",      # language code for transcription\n",
    "    \"language_detection\": False,# whether to detect dominant language in audio\n",
    "    \"punctuate\": False,         # Whether to punctuate transcript or not\n",
    "    \"format_text\": False,       # wheter to format transcript or not\n",
    "    # \"custom_spelling\": custom_spellings,    # Custom spellings of words\n",
    "    \"word_boost\": word_boost,   # For custom vocabulary\n",
    "    \"boost_param\": boost_param, # weights for words in custom vocabulary\n",
    "    \"dual_channel\": True,      # Wheter to transcript for channel separately\n",
    "    \"disfluencies\": True,       # True to include filler words else False\n",
    "    \"filter_profanity\": True,   # Whether to remove profanity from transcript\n",
    "    \"audio_start_from\": 5000,   # in ms\n",
    "    \"audio_end_at\": 45000,      # in ms    \n",
    "    \n",
    "}\n",
    "# ----------------------------------------------------------------------------------\n",
    "srt_vtt_export_params = {\n",
    "    \"chars_per_caption\": 32\n",
    "}\n",
    "# ----------------------------------------------------------------------------------\n",
    "words_to_search =[\"quarterback\", \"draft\", \"veteran\"]\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Transcribe the audio file using the upload URL\n",
    "transcript, words_search_response, transcript_in_export_format, segmented_transcript  = create_transcript(your_api_token, \n",
    "                                                                                                          data,\n",
    "                                                                                                          export_format='vtt',\n",
    "                                                                                                          transcript_export_params=srt_vtt_export_params,\n",
    "                                                                                                          words_to_search=[\"ixigo\", \"direct\", \"return\"],\n",
    "                                                                                                          segmentation_type='sentences'\n",
    "                                                                                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the completed transcript object\n",
    "pprint(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print output of each channel separately for dual_channel_transcription\n",
    "if \"utterances\" in transcript and transcript[\"utterances\"] is not None:\n",
    "    for json_obj in transcript[\"utterances\"]:\n",
    "        print(f'channel {json_obj[\"channel\"]}: {wrap(json_obj[\"text\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results of word search in transcript\n",
    "pprint(words_search_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result of transcript export to srt/vtt format\n",
    "pprint(transcript_in_export_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paragraphs/Sentence segmented transcript\n",
    "pprint(segmented_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
